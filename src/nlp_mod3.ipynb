{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_mod3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTAu_ZAVRO_P"
      },
      "source": [
        "total_samples = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klfVSCKALf1J",
        "outputId": "071ee602-c609-46cf-a01f-b0193b9b7b18"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJwW4EcxMT2V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import tensorflow_datasets as tfds\n",
        "import pickle\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoyzT11TZIA0"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW7CpeTMADRq"
      },
      "source": [
        "train = tf.data.TextLineDataset(\"/content/drive/MyDrive/data/sentences_file.txt\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBD_Guxrs5Rf"
      },
      "source": [
        "def custom_standard(input_string):\n",
        "    return tf.strings.lower(input_string)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4AVEdtsuPwc"
      },
      "source": [
        "maxlen=20 # max sequence length\n",
        "vectorize_layer_train = TextVectorization(\n",
        "    standardize=custom_standard,\n",
        "    max_tokens=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16BoqURPEvh"
      },
      "source": [
        "vectorize_layer_train.adapt(train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBHws3GpmseV",
        "outputId": "f6824226-f406-409e-9247-dba5eb712682"
      },
      "source": [
        "vocab = vectorize_layer_train.get_vocabulary()\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d63nY0hXrGc1"
      },
      "source": [
        "def prepare_train_X1(text):\n",
        "    '''\n",
        "    text = [1,2,3,4,5] seq_len = 4\n",
        "    x = [1,2,3,4] y = [2,3,4,5]\n",
        "    '''\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer_train(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    #y = tokenized_sentences[:, 1:]\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtisihK1tyGj"
      },
      "source": [
        "def prepare_train_y1(text):\n",
        "    '''\n",
        "    text = [1,2,3,4,5] seq_len = 4\n",
        "    x = [1,2,3,4] y = [2,3,4,5]\n",
        "    '''\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer_train(text)\n",
        "    #x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return y"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3HcTMAriRX"
      },
      "source": [
        "X1,y1 = train.map(prepare_train_X1),train.map(prepare_train_y1)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQy9LfZhsxGm"
      },
      "source": [
        "lids = tf.data.TextLineDataset(\"/content/drive/MyDrive/data/lid_file.txt\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poJv1vADus2q"
      },
      "source": [
        "maxlen=20 # max sequence length\n",
        "vectorize_layer_lids = TextVectorization(\n",
        "    standardize=None,\n",
        "    max_tokens=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixbg55GYuzdB"
      },
      "source": [
        "vectorize_layer_lids.adapt(lids)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSfpmT1ku6Li",
        "outputId": "77cb9375-8a37-4ead-9d86-8d124fc15ffe"
      },
      "source": [
        "vocab_lids = vectorize_layer_lids.get_vocabulary()\n",
        "vocab_lids_size = len(vocab_lids)\n",
        "print(vocab_lids_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64h5oHibvCfk",
        "outputId": "a597560e-ee3a-4d8f-88ed-3a647ebc7391"
      },
      "source": [
        "print(vocab_lids)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '[UNK]', '1', '0', '2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anjw1QyvviAL"
      },
      "source": [
        "def prepare_lids_X2(text):\n",
        "    '''\n",
        "    text = [1,2,3,4,5] seq_len = 4\n",
        "    x = [1,2,3,4] y = [2,3,4,5]\n",
        "    '''\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer_train(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    #y = tokenized_sentences[:, 1:]\n",
        "    return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um2fPFbevlsB"
      },
      "source": [
        "def prepare_lids_y2(text):\n",
        "    '''\n",
        "    text = [1,2,3,4,5] seq_len = 4\n",
        "    x = [1,2,3,4] y = [2,3,4,5]\n",
        "    '''\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer_train(text)\n",
        "    #x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a4DhDxYwCw_"
      },
      "source": [
        "X2,y2 = lids.map(prepare_lids_X2),lids.map(prepare_lids_y2)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng-TMLkh3TEJ"
      },
      "source": [
        "seq_length = 20\n",
        "embed_dim = 50\n",
        "lstm_cells = 50\n",
        "dense_cells = 100"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWKgrSVk8lux"
      },
      "source": [
        "from keras.layers.merge import concatenate"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QPQJYnUwZCP"
      },
      "source": [
        "def get_model():\n",
        "  inputs1 = tf.keras.layers.Input(shape=(seq_length))\n",
        "  embed1 = tf.keras.layers.Embedding(vocab_size,embed_dim, input_length=seq_length)(inputs1)\n",
        "  lstm1 = tf.keras.layers.LSTM(lstm_cells, return_sequences=True)(embed1)\n",
        "  dense1 = tf.keras.layers.Dense(dense_cells, activation='relu')(lstm1)\n",
        "\n",
        "  inputs2 = tf.keras.layers.Input(shape=(seq_length))\n",
        "  embed2 = tf.keras.layers.Embedding(vocab_size,embed_dim, input_length=seq_length)(inputs2)\n",
        "  lstm2 = tf.keras.layers.LSTM(lstm_cells, return_sequences=True)(embed2)\n",
        "  dense2 = tf.keras.layers.Dense(dense_cells, activation='relu')(lstm2)\n",
        "\n",
        "  merged = concatenate([dense1, dense2])\n",
        "  dense_merged = tf.keras.layers.Dense(dense_cells,activation='relu')(merged)\n",
        "\n",
        "  word_dense = tf.keras.layers.Dense(vocab_size)(dense_merged)\n",
        "\n",
        "\n",
        "  model = tf.keras.Model(inputs=[inputs1,inputs2], outputs=[word_dense])\n",
        "  return model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F38ZSGBd3KsF"
      },
      "source": [
        "l_model = get_model()\n",
        "loss_fn1 = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "l_model.compile(\"adam\", loss=[loss_fn1])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjgYFIRY3sY8",
        "outputId": "3f7d5428-f97b-4f6f-cc83-912bb7ef3dba"
      },
      "source": [
        "l_model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 50)       1418800     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 20, 50)       1418800     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 20, 50)       20200       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 20, 50)       20200       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 100)      5100        lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 100)      5100        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 20, 200)      0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20, 100)      20100       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 20, 28376)    2865976     dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 5,774,276\n",
            "Trainable params: 5,774,276\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_t_sXW2J24P"
      },
      "source": [
        "lt = []\n",
        "for i in X1:\n",
        "  lt.append(i.numpy())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbQ7cH0JKg6G"
      },
      "source": [
        "ut = []\n",
        "for i in X2:\n",
        "  ut.append(i.numpy())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4weRQuxKrnI"
      },
      "source": [
        "ik = []\n",
        "for i in y1:\n",
        "  ik.append(i.numpy())"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQRDZTnJK0At"
      },
      "source": [
        "mk = []\n",
        "for i in y2:\n",
        "  mk.append(i.numpy())"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL5iuIhuK4WF"
      },
      "source": [
        "x_1 = np.array(lt).reshape(16220,-1,)\n",
        "x_2 = np.array(ut).reshape(16220,-1,)\n",
        "y_1 = np.array(ik).reshape(16220,-1,)\n",
        "y_2 = np.array(mk).reshape(16220,-1,)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBRF4_cVcN5x"
      },
      "source": [
        "sample = 8000"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5gQZKt4MbfW"
      },
      "source": [
        "class Custom_Saver_for_lm(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if(epoch%4 == 0):\n",
        "        self.model.save(\"/content/drive/MyDrive/fin_model/\"+str(epoch)+\"/model/\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFmbn3leMuSD"
      },
      "source": [
        "saver_final = Custom_Saver_for_lm()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It928OaqZisT",
        "outputId": "5071c55e-f086-4f19-c8b2-795b364fd6d5"
      },
      "source": [
        "l_model.fit(x=[x_1[:sample],x_2[:sample]],y=y_1[:sample],epochs = 10,callbacks=[saver_final])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "250/250 [==============================] - 10s 37ms/step - loss: 5.3120\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/0/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/0/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "250/250 [==============================] - 9s 38ms/step - loss: 5.1288\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.9699\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.8481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/3/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/3/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.7369\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.6321\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.5324\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/6/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/6/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10\n",
            "250/250 [==============================] - 9s 37ms/step - loss: 4.4355\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 9s 36ms/step - loss: 4.3388\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 9s 36ms/step - loss: 4.2417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/9/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/9/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb17df316d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guTkiYVKNoM6",
        "outputId": "2b74cad9-79f2-40d2-a5d7-30650b5d72a3"
      },
      "source": [
        "l_model.save(\"/content/drive/MyDrive/fin_model/\"+str(10)+\"/model/\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/10/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/fin_model/10/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2to5WvOB5y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wirO26ZbFHY_"
      },
      "source": [
        "class TextGenerator():\n",
        "    def __init__( \n",
        "        self, max_tokens, start_tokens, index_to_word, top_k=10,maxlen=20):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "        self.index_to_word = index_to_word\n",
        "        self.k = top_k\n",
        "        self.maxlen=maxlen\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype(\"int32\")\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype(\"float32\")\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "    def detokenize(self, number):\n",
        "        return self.index_to_word[number]\n",
        "\n",
        "    def get_sen(self, model):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        # print(start_tokens)\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            pad_len = self.maxlen - len(start_tokens)\n",
        "            sample_index = len(start_tokens) - 1\n",
        "            if pad_len < 0:\n",
        "                x = start_tokens[:self.maxlen]\n",
        "                sample_index = self.maxlen - 1\n",
        "            elif pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "            else:\n",
        "                x = start_tokens\n",
        "            x = np.array([x])\n",
        "            print(x)\n",
        "            num_tokens_generated+=1 #rem\n",
        "        #     y = model.predict([x)\n",
        "        #     sample_token = self.sample_from(y[0][sample_index])\n",
        "        #     tokens_generated.append(sample_token)\n",
        "        #     start_tokens.append(sample_token)\n",
        "        #     num_tokens_generated = len(tokens_generated)\n",
        "        # txt = \" \".join(\n",
        "        #     [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
        "        # )\n",
        "        # return txt"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TonGf5BXxr2_"
      },
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/naive_model/naive_simple_model_20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djttb5fSx_KK"
      },
      "source": [
        "start_prompt = \"ye sab kya\"\n",
        "word_to_index = {}\n",
        "for index, word in enumerate(vocab):\n",
        "    word_to_index[word] = index\n",
        "word_to_lid = {}\n",
        "for index, word in enumerate(vocab_lids):\n",
        "    word_to_lid[word] = index\n",
        "num_tokens_generated = 100\n",
        "start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]\n",
        "lid_tokens = [word_to_lid.get(_,1) for _ in start_prompt.split()]"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZXUmORFRZp"
      },
      "source": [
        "gen = TextGenerator(num_tokens_generated, start_tokens, vocab,lid_tokens,vocab_lid)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfN_-t-7QMOV",
        "outputId": "68382849-67db-4df8-c88a-3f6b427f9d41"
      },
      "source": [
        "gen.get_sen(model=None)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "[[18 52 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHt6UwVdOuOU",
        "outputId": "0d4efc03-a7d5-4704-e476-be5180b672c0"
      },
      "source": [
        "print(start_tokens)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 52, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QCrCUPcXPS-_",
        "outputId": "cf06389b-5c92-45b0-8b91-c54fe4822e40"
      },
      "source": [
        "l_model.predict([start_tokens,[1,1,1]])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-1293bde8f5d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ml_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 3) dtype=int64>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KJ-XUaWHbHu",
        "outputId": "62a430f1-1fb4-4dd7-d5c9-9271f19f05bd"
      },
      "source": [
        "gen.get_sen(l_model)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18, 52, 22]\n",
            "[18, 52, 22]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}