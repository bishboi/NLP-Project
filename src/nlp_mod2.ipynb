{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_mod2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTAu_ZAVRO_P"
      },
      "source": [
        "total_samples = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQVpVm4xPql2"
      },
      "source": [
        "f = open(\"/content/drive/MyDrive/small_train_\"+str(total_samples)+\".txt\", \"w\")\n",
        "for line in train.take(total_samples):\n",
        "  f.write(line.numpy().decode()+'\\n')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klfVSCKALf1J",
        "outputId": "668d9c12-dfe0-4f18-f152-6f8ac8464dd2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJwW4EcxMT2V"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "import random\n",
        "import tensorflow_datasets as tfds\n",
        "import pickle\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoyzT11TZIA0"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW7CpeTMADRq"
      },
      "source": [
        "train = tf.data.TextLineDataset(\"/content/drive/MyDrive/data/sentences_file.txt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBD_Guxrs5Rf"
      },
      "source": [
        "def custom_standard(input_string):\n",
        "    return tf.strings.lower(input_string)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4AVEdtsuPwc"
      },
      "source": [
        "maxlen=20 # max sequence length\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standard,\n",
        "    max_tokens=None,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=maxlen + 1,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r16BoqURPEvh"
      },
      "source": [
        "vectorize_layer.adapt(train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJV856Kt0rL",
        "outputId": "762ecc62-b53c-4031-f43e-b277757abe25"
      },
      "source": [
        "for i in train.take(2):\n",
        "  print(i.numpy().decode())\n",
        "# data is lowercased"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ye to hona hi tha .... kabhi kisi neta ko saja mili hi ... always clean chit .. \n",
            "hey frd . hw r u ? msg now \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3qur3U0Rtg_"
      },
      "source": [
        "vocab = vectorize_layer.get_vocabulary()\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1Dh5k3ktTbx",
        "outputId": "6891ee27-2a90-4375-d504-f2e802341a72"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lluMtwIX9g8X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3eAklhTTMd"
      },
      "source": [
        "def prepare_dataset(text):\n",
        "    '''\n",
        "    text = [1,2,3,4,5] seq_len = 4\n",
        "    x = [1,2,3,4] y = [2,3,4,5]\n",
        "    '''\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5doJnm3cTXww"
      },
      "source": [
        "train_ds = train.map(prepare_dataset) # train_ds[0] = tuple(x[0],y[0])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jFdUMNZH3e4",
        "outputId": "cf5df1b5-eed9-402b-fb78-6220f6287521"
      },
      "source": [
        "type(train_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.MapDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEzohfySTCtq",
        "outputId": "d058dd22-ee07-48b8-f52f-a62c7f759ec9"
      },
      "source": [
        "# data is tokenised and ready for the model\n",
        "for i in train_ds.take(1):\n",
        "  print(i[0].numpy())\n",
        "  print(i[1].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  18    4  193   19   48   28  216   87  221    5  780 1054   19   13\n",
            "   922 1641 3479   16    0    0]]\n",
            "[[   4  193   19   48   28  216   87  221    5  780 1054   19   13  922\n",
            "  1641 3479   16    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NVjlDFoZ_Z3"
      },
      "source": [
        "seq_length = 20\n",
        "embed_dim = 50\n",
        "lstm_cells = 50\n",
        "dense_cells = 100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1uT19RWXij-"
      },
      "source": [
        "def complex_naive():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim, input_length=seq_length))\n",
        "  model.add(LSTM(lstm_cells, return_sequences=True))\n",
        "  model.add(Dense(dense_cells, activation='relu'))\n",
        "  model.add( tf.keras.layers.Dropout(0.2))\n",
        "  model.add(Dense(vocab_size))\n",
        "  #loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(\"adam\", loss='sparse_categorical_crossentropy')\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aijjVnLObdcj"
      },
      "source": [
        "def simple_naive():\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size,embed_dim, input_length=seq_length))\n",
        "  model.add(LSTM(lstm_cells, return_sequences=True))\n",
        "  model.add(Dense(vocab_size))\n",
        "  #loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  model.compile(\"adam\",loss='sparse_categorical_crossentropy')\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PzqouhV3f4U"
      },
      "source": [
        "#simple naive\n",
        "class Custom_Saver_for_complex_naive(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      if(epoch%3 == 0):\n",
        "        self.model.save(\"/content/drive/MyDrive/naive_complex_model/\"+str(epoch)+\"/model/\")\n",
        "        #self.model.save(\"/content/drive/MyDrive/naive_model/naive_simple_model_\"+str(epoch)+\".hd5\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B03M86yEMvEe",
        "outputId": "aa5507b7-5379-4c4d-b958-08296d4a0cc2"
      },
      "source": [
        "naive_complex_model = complex_naive()\n",
        "print(naive_complex_model.summary())\n",
        "saver_complex = Custom_Saver_for_complex_naive()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 50)            1418800   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 20, 50)            20200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20, 100)           5100      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20, 28376)         2865976   \n",
            "=================================================================\n",
            "Total params: 4,310,076\n",
            "Trainable params: 4,310,076\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncDwJAloD32v",
        "outputId": "452e1f07-4b35-4557-8a94-73fe7dbbb0af"
      },
      "source": [
        "print(type(train_ds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwmQCu0Mwkkp",
        "outputId": "e1d1b97e-0e92-44df-ce61-f9d1dcba1126"
      },
      "source": [
        "naive_complex_model.fit(train_ds,epochs=10,callbacks=[saver_complex])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16220/16220 [==============================] - 286s 16ms/step - loss: 10.2401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/0/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/0/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "16220/16220 [==============================] - 265s 16ms/step - loss: 9.6619\n",
            "Epoch 3/10\n",
            "16220/16220 [==============================] - 260s 16ms/step - loss: 7.6091\n",
            "Epoch 4/10\n",
            "16220/16220 [==============================] - 259s 16ms/step - loss: 7.6078\n",
            "Epoch 5/10\n",
            "16220/16220 [==============================] - 256s 16ms/step - loss: 7.6078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/4/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/4/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10\n",
            "16220/16220 [==============================] - 254s 16ms/step - loss: 7.6078\n",
            "Epoch 7/10\n",
            "16220/16220 [==============================] - 270s 17ms/step - loss: 7.6077\n",
            "Epoch 8/10\n",
            "16220/16220 [==============================] - 262s 16ms/step - loss: 7.6078\n",
            "Epoch 9/10\n",
            "16220/16220 [==============================] - 272s 17ms/step - loss: 7.6077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/8/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/8/model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10\n",
            "16220/16220 [==============================] - 288s 18ms/step - loss: 7.6078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7088ce68d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF7H2zd1MusF",
        "outputId": "72e58794-f94a-4a25-a53b-340f2f490eb6"
      },
      "source": [
        "naive_complex_model.save(\"/content/drive/MyDrive/naive_complex_model/10/model/\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/10/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/naive_complex_model/10/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TonGf5BXxr2_"
      },
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/naive_model/naive_simple_model_20')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wirO26ZbFHY_"
      },
      "source": [
        "class TextGenerator():\n",
        "    def __init__(\n",
        "        self, max_tokens, start_tokens, index_to_word, top_k=10,maxlen=20):\n",
        "        self.max_tokens = max_tokens\n",
        "        self.start_tokens = start_tokens\n",
        "        self.index_to_word = index_to_word\n",
        "        self.k = top_k\n",
        "        self.maxlen=maxlen\n",
        "\n",
        "    def sample_from(self, logits):\n",
        "        logits, indices = tf.math.top_k(logits, k=self.k, sorted=True)\n",
        "        indices = np.asarray(indices).astype(\"int32\")\n",
        "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
        "        preds = np.asarray(preds).astype(\"float32\")\n",
        "        return np.random.choice(indices, p=preds)\n",
        "\n",
        "    def detokenize(self, number):\n",
        "        return self.index_to_word[number]\n",
        "\n",
        "    def get_sen(self, model):\n",
        "        start_tokens = [_ for _ in self.start_tokens]\n",
        "        num_tokens_generated = 0\n",
        "        tokens_generated = []\n",
        "        while num_tokens_generated <= self.max_tokens:\n",
        "            pad_len = self.maxlen - len(start_tokens)\n",
        "            sample_index = len(start_tokens) - 1\n",
        "            if pad_len < 0:\n",
        "                x = start_tokens[:self.maxlen]\n",
        "                sample_index = self.maxlen - 1\n",
        "            elif pad_len > 0:\n",
        "                x = start_tokens + [0] * pad_len\n",
        "            else:\n",
        "                x = start_tokens\n",
        "            x = np.array([x])\n",
        "            y = model.predict(x)\n",
        "            sample_token = self.sample_from(y[0][sample_index])\n",
        "            tokens_generated.append(sample_token)\n",
        "            start_tokens.append(sample_token)\n",
        "            num_tokens_generated = len(tokens_generated)\n",
        "        txt = \" \".join(\n",
        "            [self.detokenize(_) for _ in self.start_tokens + tokens_generated]\n",
        "        )\n",
        "        return txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djttb5fSx_KK"
      },
      "source": [
        "word_to_index = {}\n",
        "for index, word in enumerate(vocab):\n",
        "    word_to_index[word] = index\n",
        "num_tokens_generated = 100\n",
        "start_tokens = [word_to_index.get(_, 1) for _ in start_prompt.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuZXUmORFRZp"
      },
      "source": [
        "start_prompt = \"ye sab kya\"\n",
        "gen = TextGenerator(num_tokens_generated, start_tokens, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "0KJ-XUaWHbHu",
        "outputId": "cb2e7117-163a-4a90-ac9a-1d8430ecf7e5"
      },
      "source": [
        "gen.get_sen(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ye sab kya waar pellet di prayer prayer sochana prayer potli tmari fenkte fenkte ilzaam fenkte smone krantikari prayer krantikari tmari potli potli govment fenkte patidar krantikari govment potli tmari prayer fenkte tmari waar patidar krantikari tmari prayer tmari krantikari tmari krantikari prayer potli potli tmari potli ilzaam patidar prayer fenkte krantikari ilzaam potli fenkte krantikari tmari prayer prayer potli krantikari krantikari patidar smone ilzaam patidar tmari govment smone fenkte potli potli smone tmari fenkte ilzaam waar patidar patidar ilzaam prayer prayer prayer smone govment tmari krantikari krantikari patidar potli potli ilzaam krantikari prayer smone fenkte tmari govment fenkte waar govment smone govment fenkte'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    }
  ]
}